{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk, filedialog\n",
    "from google.colab import drive\n",
    "from __future__ import absolute_import, print_function, division, unicode_literals\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dropout, Dense\n",
    "from keras import regularizers\n",
    "\n",
    "# Function to open the file dialog and get the selected directory\n",
    "def select_dataset_directory():\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "    dataset_dir = filedialog.askdirectory(title=\"Select Dataset Directory\")\n",
    "    root.destroy()\n",
    "    return dataset_dir\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Select the dataset directory using the GUI\n",
    "data_dir = select_dataset_directory()\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "CLASS_NAMES = np.array(['Bacterial leaf blight', 'Brown Spot', 'Leaf Smut'])\n",
    "\n",
    "print('Class Names: ', CLASS_NAMES)\n",
    "\n",
    "train_path = '/content/drive/MyDrive/Dataset'\n",
    "test_path = '/content/drive/MyDrive/Dataset'\n",
    "\n",
    "image_train_gen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                     zoom_range=0.50,\n",
    "                                     rotation_range=45,\n",
    "                                     horizontal_flip=True,\n",
    "                                     width_shift_range=0.15,\n",
    "                                     height_shift_range=0.15)\n",
    "\n",
    "train_data_gen = image_train_gen.flow_from_directory(train_path,\n",
    "                                                     shuffle=True,\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='sparse')\n",
    "\n",
    "img_val_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "val_data_gen = img_val_gen.flow_from_directory(test_path,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                               class_mode='sparse')\n",
    "\n",
    "def plotImages(image_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(image_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot a few training images\n",
    "img_array = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(img_array)\n",
    "\n",
    "# Plot a few validation images\n",
    "img_array = [val_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(img_array)\n",
    "\n",
    "# Model building\n",
    "# Instantiate a ConvNet\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), input_shape=(224, 224, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "EPOCHS = 70\n",
    "history = model.fit_generator(train_data_gen, epochs=EPOCHS, validation_data=val_data_gen)\n",
    "\n",
    "# Plot training and validation graphs\n",
    "acc = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
